import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import numpy as np
from nltk.corpus import stopwords, wordnet
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, recall_score, f1_score
from gensim.models import Word2Vec
from mpl_toolkits.mplot3d import Axes3D

# Download necessary NLTK resources
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('punkt')

# Load the dataset
file_path = "/Phishing_Email.csv"
data = pd.read_csv(file_path)

# Data Cleaning
data.drop('Unnamed: 0', axis=1, inplace=True, errors='ignore')
data.dropna(subset=['Email Text'], inplace=True)
data.drop_duplicates(inplace=True)

# Text Preprocessing
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return tokens

# Apply preprocessing
data['Tokens'] = data['Email Text'].apply(preprocess_text)
data['Cleaned Text'] = data['Tokens'].apply(lambda x: ' '.join(x))

# Prepare data for model
X = data['Cleaned Text']
y = data['Email Type']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_train_tokens = data.loc[X_train.index, 'Tokens']
X_test_tokens = data.loc[X_test.index, 'Tokens']

# ---- TF-IDF Model ----
vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', min_df=2, max_df=0.7, ngram_range=(1, 2))
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

from sklearn.neural_network import MLPClassifier

# Train MLP Classifier with TF-IDF
model_tfidf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
model_tfidf.fit(X_train_tfidf, y_train)

# Predict and evaluate the TF-IDF model
y_pred_tfidf = model_tfidf.predict(X_test_tfidf)
report_tfidf = classification_report(y_test, y_pred_tfidf)

# ---- Word2Vec Model ----
word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4, sg=0)
word2vec_model.train(X_train_tokens, total_examples=len(X_train_tokens), epochs=10)

# Convert text to Word2Vec embeddings
def get_word2vec_embeddings(tokens):
    embeddings = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]
    return np.mean(embeddings, axis=0) if embeddings else np.zeros(100)

X_train_w2v = np.array([get_word2vec_embeddings(tokens) for tokens in X_train_tokens])
X_test_w2v = np.array([get_word2vec_embeddings(tokens) for tokens in X_test_tokens])

from sklearn.neural_network import MLPClassifier

# Train MLP Classifier with Word2Vec
model_w2v = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)
model_w2v.fit(X_train_w2v, y_train)

# Predict and evaluate the Word2Vec model
y_pred_w2v = model_w2v.predict(X_test_w2v)
report_w2v = classification_report(y_test, y_pred_w2v)

# ---- Confusion Matrices ----
cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)
cm_w2v = confusion_matrix(y_test, y_pred_w2v)

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# TF-IDF Confusion Matrix
sns.heatmap(cm_tfidf, annot=True, fmt="d", cmap="Blues", xticklabels=model_tfidf.classes_, yticklabels=model_tfidf.classes_, ax=axes[0])
axes[0].set_title("TF-IDF Confusion Matrix")
axes[0].set_xlabel("Predicted")
axes[0].set_ylabel("Actual")

# Word2Vec Confusion Matrix
sns.heatmap(cm_w2v, annot=True, fmt="d", cmap="Oranges", xticklabels=model_w2v.classes_, yticklabels=model_w2v.classes_, ax=axes[1])
axes[1].set_title("Word2Vec Confusion Matrix")
axes[1].set_xlabel("Predicted")
axes[1].set_ylabel("Actual")

plt.show()

# ---- 3D Bar Graph for Key Metrics ----
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
tfidf_scores = [
    accuracy_score(y_test, y_pred_tfidf) * 100,
    precision_score(y_test, y_pred_tfidf, average='weighted') * 100,
    recall_score(y_test, y_pred_tfidf, average='weighted') * 100,
    f1_score(y_test, y_pred_tfidf, average='weighted') * 100
]

w2v_scores = [
    accuracy_score(y_test, y_pred_w2v) * 100,
    precision_score(y_test, y_pred_w2v, average='weighted') * 100,
    recall_score(y_test, y_pred_w2v, average='weighted') * 100,
    f1_score(y_test, y_pred_w2v, average='weighted') * 100
]

fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

x_pos = np.arange(len(metrics))
y_pos = [0, 1]

bar_width = 0.4

for i, metric in enumerate(metrics):
    ax.bar3d(x_pos[i], y_pos[0], 0, bar_width, bar_width, tfidf_scores[i], color='green', shade=True)
    ax.bar3d(x_pos[i], y_pos[1], 0, bar_width, bar_width, w2v_scores[i], color='blue', shade=True)

ax.set_xlabel('Metrics')
ax.set_ylabel('Models')
ax.set_zlabel('Score (%)')
ax.set_title('3D Performance Comparison of TF-IDF and Word2Vec')

ax.set_xticks(x_pos)
ax.set_xticklabels(metrics)
ax.set_yticks(y_pos)
ax.set_yticklabels(['TF-IDF', 'Word2Vec'])

plt.show()

# ---- Print Full Classification Reports ----
print("\n----- TF-IDF Model Classification Report -----")
print(report_tfidf)

print("\n----- Word2Vec Model Classification Report -----")
print(report_w2v)
